"""
Markdown rendering utilities for ASP platform.

This module provides functions for converting agent artifacts
(Pydantic models) into human-readable Markdown format.

Implements the markdown rendering from:
docs/artifact_persistence_version_control_decision.md

Author: ASP Development Team
Date: November 17, 2025
"""

import logging
from datetime import datetime
from typing import Any

from asp.models.code import GeneratedCode
from asp.models.code_review import CodeReviewReport
from asp.models.design import DesignSpecification
from asp.models.design_review import DesignReviewReport
from asp.models.planning import ProjectPlan

logger = logging.getLogger(__name__)


def render_plan_markdown(plan: ProjectPlan) -> str:
    """
    Render ProjectPlan as human-readable Markdown.

    Args:
        plan: ProjectPlan Pydantic model

    Returns:
        Markdown formatted string

    Example:
        >>> markdown = render_plan_markdown(project_plan)
        >>> "# Project Plan:" in markdown
        True
    """
    # Build header with available fields
    md = f"""# Project Plan: {plan.task_id}

**Project ID:** {plan.project_id or "N/A"}
**Task ID:** {plan.task_id}
**Total Complexity:** {plan.total_est_complexity}
**PROBE-AI Enabled:** {plan.probe_ai_enabled}
**Agent Version:** {plan.agent_version}

"""

    # Add PROBE-AI predictions if available
    if plan.probe_ai_prediction:
        md += f"""## PROBE-AI Predictions

**Estimated Effort:** {plan.probe_ai_prediction.total_effort_hours:.1f} hours
**Estimated Cost:** ${plan.probe_ai_prediction.total_cost:.2f}
**Confidence:** {plan.probe_ai_prediction.confidence:.1%}

"""

    md += "## Task Decomposition\n\n"

    # Add semantic units
    for i, unit in enumerate(plan.semantic_units, 1):
        md += f"""### {unit.unit_id}: {unit.description}

- **Estimated Complexity:** {unit.est_complexity}
- **API Interactions:** {unit.api_interactions}
- **Data Transformations:** {unit.data_transformations}
- **Logical Branches:** {unit.logical_branches}
- **Code Entities Modified:** {unit.code_entities_modified}
- **Novelty Multiplier:** {unit.novelty_multiplier}
- **Dependencies:** {", ".join(unit.dependencies) if unit.dependencies else "None"}

"""

    return md


def render_design_markdown(design: DesignSpecification) -> str:
    """
    Render DesignSpecification as human-readable Markdown.

    Args:
        design: DesignSpecification Pydantic model

    Returns:
        Markdown formatted string
    """
    md = f"""# Design Specification: {design.task_id}

**Task ID:** {design.task_id}

## Architecture Overview

{design.architecture_overview}

## Technology Stack

{design.technology_stack}

## Assumptions

{design.assumptions}

"""

    # Add API contracts
    if design.api_contracts:
        md += "## API Contracts\n\n"
        for api in design.api_contracts:
            md += f"""### {api.method} {api.endpoint}

- **Description:** {api.description}
- **Authentication:** {api.authentication_required}
"""
            if api.request_schema:
                md += f"- **Request Schema:**\n```json\n{api.request_schema}\n```\n"
            if api.response_schema:
                md += f"- **Response Schema:**\n```json\n{api.response_schema}\n```\n"
            if api.error_responses:
                # error_responses is a list of dicts with status_code and description
                error_summary = ", ".join([f"{e.get('status_code', 'N/A')}" for e in api.error_responses])
                md += f"- **Error Responses:** {error_summary}\n"

            md += "\n"

    # Add data schemas
    if design.data_schemas:
        md += "## Data Schemas\n\n"
        for schema in design.data_schemas:
            md += f"""### {schema.table_name}

- **Description:** {schema.description}
"""
            if schema.fields:
                md += "- **Fields:**\n"
                for field in schema.fields:
                    md += f"  - `{field}`\n"
            if schema.indexes:
                md += f"- **Indexes:** {', '.join(schema.indexes)}\n"
            if schema.relationships:
                md += f"- **Relationships:** {', '.join(schema.relationships)}\n"

            md += "\n"

    # Add component logic
    if design.component_logic:
        md += "## Component Logic\n\n"
        for component in design.component_logic:
            md += f"""### {component.component_name}

- **Responsibility:** {component.responsibility}
- **Semantic Unit:** {component.semantic_unit_id}
- **Dependencies:** {', '.join(component.dependencies) if component.dependencies else 'None'}
- **Implementation Notes:** {component.implementation_notes}
"""
            if component.interfaces:
                md += "- **Interfaces:**\n"
                for interface in component.interfaces:
                    md += f"  - `{interface.get('method', 'N/A')}`\n"

            md += "\n"

    # Add metadata
    md += f"""---

*Generated by Design Agent on {design.timestamp.strftime('%Y-%m-%d %H:%M:%S')}*
"""

    return md


def render_design_review_markdown(review: DesignReviewReport) -> str:
    """
    Render DesignReviewReport as human-readable Markdown.

    Args:
        review: DesignReviewReport Pydantic model

    Returns:
        Markdown formatted string
    """
    md = f"""# Design Review Report: {review.task_id}

**Review ID:** {review.review_id}
**Review Status:** {review.review_status}
**Reviewed by:** Design Review Agent v{review.agent_version}
**Date:** {review.review_timestamp}

## Summary

- **Total Issues:** {review.total_issues}
- **Critical:** {review.critical_issues}
- **High:** {review.high_issues}
- **Medium:** {review.medium_issues}
- **Low:** {review.low_issues}

"""

    # Add issues by severity
    if review.critical_issues > 0:
        md += "## Critical Issues\n\n"
        for issue in review.issues_found:
            if issue.severity == "Critical":
                md += f"""### {issue.issue_id}: {issue.description}

**Category:** {issue.category}
**Severity:** {issue.severity}
**Affected Phase:** {issue.affected_phase}
**Evidence:** {issue.evidence}

{issue.impact}

"""

    if review.high_issues > 0:
        md += "## High Issues\n\n"
        for issue in review.issues_found:
            if issue.severity == "High":
                md += f"""### {issue.issue_id}: {issue.description}

**Category:** {issue.category}
**Evidence:** {issue.evidence}

{issue.impact}

"""

    if review.medium_issues > 0:
        md += "## Medium Issues\n\n"
        for issue in review.issues_found:
            if issue.severity == "Medium":
                md += f"- **{issue.issue_id}**: {issue.description} ({issue.category})\n"
        md += "\n"

    if review.low_issues > 0:
        md += "## Low Issues\n\n"
        for issue in review.issues_found:
            if issue.severity == "Low":
                md += f"- **{issue.issue_id}**: {issue.description} ({issue.category})\n"
        md += "\n"

    # Add improvement suggestions
    if review.improvement_suggestions:
        md += "## Improvement Suggestions\n\n"
        for suggestion in review.improvement_suggestions:
            if suggestion.priority == "High":
                md += f"""### {suggestion.suggestion_id}: {suggestion.description}

**Priority:** {suggestion.priority}
**Category:** {suggestion.category}
"""
                if suggestion.related_issue_id:
                    md += f"**Addresses:** {suggestion.related_issue_id}\n"

                md += f"\n{suggestion.implementation_notes}\n\n"

    # Add phase-aware breakdown
    if review.planning_phase_issues or review.design_phase_issues:
        md += "## Phase-Aware Issue Breakdown\n\n"
        if review.planning_phase_issues:
            md += f"- **Planning Phase Issues:** {len(review.planning_phase_issues)}\n"
        if review.design_phase_issues:
            md += f"- **Design Phase Issues:** {len(review.design_phase_issues)}\n"
        md += "\n"

    # Add metadata
    if review.review_duration_seconds:
        md += f"""---

*Review completed in {review.review_duration_seconds:.1f} seconds*
"""

    return md


def render_code_manifest_markdown(code: GeneratedCode) -> str:
    """
    Render GeneratedCode metadata as human-readable Markdown.

    Args:
        code: GeneratedCode Pydantic model

    Returns:
        Markdown formatted string
    """
    md = f"""# Code Generation Manifest: {code.task_id}

**Project ID:** {code.project_id or "N/A"}
**Generated by:** Code Agent v{code.agent_version}
**Timestamp:** {code.generation_timestamp or "N/A"}

## Summary

- **Total Files:** {code.total_files}
- **Total Lines of Code:** {code.total_lines_of_code:,}
- **Test Coverage Target:** {code.test_coverage_target or 0}%

## File Structure

"""

    # Add file structure
    for directory, files in sorted(code.file_structure.items()):
        md += f"**{directory}/**\n"
        for file in sorted(files):
            md += f"- {file}\n"
        md += "\n"

    # Add generated files summary
    md += "## Generated Files\n\n"

    # Group by file type
    source_files = [f for f in code.files if f.file_type == "source"]
    test_files = [f for f in code.files if f.file_type == "test"]
    config_files = [f for f in code.files if f.file_type == "config"]
    other_files = [f for f in code.files if f.file_type not in ["source", "test", "config"]]

    if source_files:
        md += "### Source Files\n\n"
        for file in source_files:
            md += f"- `{file.file_path}` - {file.description}\n"
        md += "\n"

    if test_files:
        md += "### Test Files\n\n"
        for file in test_files:
            md += f"- `{file.file_path}` - {file.description}\n"
        md += "\n"

    if config_files:
        md += "### Configuration Files\n\n"
        for file in config_files:
            md += f"- `{file.file_path}` - {file.description}\n"
        md += "\n"

    # Add implementation notes
    md += f"""## Implementation Notes

{code.implementation_notes}

"""

    # Add dependencies
    if code.dependencies:
        md += "## Dependencies\n\n"
        md += "```\n"
        for dep in code.dependencies:
            md += f"{dep}\n"
        md += "```\n\n"

    # Add setup instructions
    if code.setup_instructions:
        md += f"""## Setup Instructions

{code.setup_instructions}

"""

    # Add traceability
    if code.semantic_units_implemented or code.components_implemented:
        md += "## Traceability\n\n"
        if code.semantic_units_implemented:
            md += f"- **Semantic Units:** {', '.join(code.semantic_units_implemented)}\n"
        if code.components_implemented:
            md += f"- **Components:** {', '.join(code.components_implemented)}\n"
        md += "\n"

    md += "---\n\n*See individual files in src/, tests/, etc. for actual code*\n"

    return md


def render_code_review_markdown(review: CodeReviewReport) -> str:
    """
    Render CodeReviewReport as human-readable Markdown.

    Args:
        review: CodeReviewReport Pydantic model

    Returns:
        Markdown formatted string
    """
    md = f"""# Code Review Report: {review.task_id}

**Review ID:** {review.review_id}
**Review Status:** {review.review_status}
**Reviewed by:** Code Review Agent v{review.agent_version}
**Date:** {review.review_timestamp}

## Summary

- **Files Reviewed:** {review.files_reviewed}
- **Lines Reviewed:** {review.total_lines_reviewed:,}
- **Total Issues:** {review.total_issues}
- **Critical:** {review.critical_issues}
- **High:** {review.high_issues}
- **Medium:** {review.medium_issues}
- **Low:** {review.low_issues}

"""

    # Add critical issues
    if review.critical_issues > 0:
        md += "## Critical Issues\n\n"
        for issue in review.issues_found:
            if issue.severity == "Critical":
                md += f"""### {issue.issue_id}: {issue.description}

**Category:** {issue.category}
**Severity:** {issue.severity}
**Affected Phase:** {issue.affected_phase}
**File:** `{issue.file_path}`
"""
                if issue.line_number:
                    md += f"**Line:** {issue.line_number}\n"

                if issue.code_snippet:
                    md += f"\n```python\n{issue.code_snippet}\n```\n"

                md += f"\n**Impact:** {issue.impact}\n\n"

    # Add high issues
    if review.high_issues > 0:
        md += "## High Issues\n\n"
        for issue in review.issues_found:
            if issue.severity == "High":
                md += f"""### {issue.issue_id}: {issue.description}

**Category:** {issue.category}
**File:** `{issue.file_path}:{issue.line_number or 'N/A'}`

{issue.impact}

"""

    # Add medium/low issues summary
    if review.medium_issues > 0 or review.low_issues > 0:
        md += "## Other Issues\n\n"
        for issue in review.issues_found:
            if issue.severity in ["Medium", "Low"]:
                md += f"- **[{issue.severity}]** {issue.issue_id}: {issue.description} (`{issue.file_path}`)\n"
        md += "\n"

    # Add improvement suggestions
    if review.improvement_suggestions:
        md += "## Improvement Suggestions\n\n"
        for suggestion in review.improvement_suggestions:
            if suggestion.priority == "High":
                md += f"""### {suggestion.suggestion_id}: {suggestion.description}

**Priority:** {suggestion.priority}
**Category:** {suggestion.category}
"""
                if suggestion.related_issue_id:
                    md += f"**Fixes:** {suggestion.related_issue_id}\n"

                md += f"\n{suggestion.implementation_notes}\n"

                if suggestion.suggested_code:
                    md += f"\n**Suggested Fix:**\n```python\n{suggestion.suggested_code}\n```\n"

                md += "\n"

    # Add specialist results
    md += """## Specialist Review Results

"""

    specialists = [
        ("Security Review", review.security_review_passed),
        ("Code Quality Review", review.quality_review_passed),
        ("Performance Review", review.performance_review_passed),
        ("Standards Compliance", review.standards_review_passed),
        ("Testing Review", review.testing_review_passed),
        ("Maintainability Review", review.maintainability_review_passed),
    ]

    for name, passed in specialists:
        status_text = "PASS" if passed else "FAIL"
        md += f"- {name}: {status_text}\n"

    md += "\n"

    # Add phase-aware breakdown
    if review.planning_phase_issues or review.design_phase_issues or review.code_phase_issues:
        md += "## Phase-Aware Issue Breakdown\n\n"
        if review.planning_phase_issues:
            md += f"- **Planning Phase Issues:** {len(review.planning_phase_issues)}\n"
        if review.design_phase_issues:
            md += f"- **Design Phase Issues:** {len(review.design_phase_issues)}\n"
        if review.code_phase_issues:
            md += f"- **Code Phase Issues:** {len(review.code_phase_issues)}\n"
        md += "\n"

    # Add metadata
    if review.review_duration_seconds:
        md += f"""---

*Review completed in {review.review_duration_seconds:.1f} seconds*
"""

    return md
